{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\r\n",
    "#The variables come from here:\r\n",
    "# https://api.census.gov/data/2019/acs/acs1/variables.html\r\n",
    "\r\n",
    "#importing packages\r\n",
    "import pandas as pd\r\n",
    "import censusdata\r\n",
    "import gc\r\n",
    "import re\r\n",
    "from unittest.mock import inplace\r\n",
    "import json\r\n",
    "import os\r\n",
    "import itertools\r\n",
    "from datetime import date\r\n",
    "import sys\r\n",
    "\r\n",
    "def get_geoid_reference_df(geographies: dict, level:str) -> pd.DataFrame:\r\n",
    "\r\n",
    "    # check level is valid \r\n",
    "\r\n",
    "    if level not in ['county', 'tract', 'blockgroup']:\r\n",
    "        raise ValueError('Invalid level')\r\n",
    "    \r\n",
    "\r\n",
    "    \"\"\"Curates the GEOID References from the geographies grab\"\"\"\r\n",
    "\r\n",
    "    #creating a dictionary to store the GEOID references\r\n",
    "    if level == 'tract':\r\n",
    "        geoid_dict = {\r\n",
    "            'GEOID': [],\r\n",
    "            'STATE': [],\r\n",
    "            'COUNTY': [], \r\n",
    "            'TRACT' : []\r\n",
    "        }        \r\n",
    "    \r\n",
    "    elif level == 'blockgroup':\r\n",
    "        geoid_dict = {\r\n",
    "            'GEOID': [],\r\n",
    "            'STATE': [],\r\n",
    "            'COUNTY': [], \r\n",
    "            'TRACT' : [], \r\n",
    "            'BLOCK_GROUP': []\r\n",
    "        }\r\n",
    "    elif level == 'county':\r\n",
    "        geoid_dict = {\r\n",
    "            'GEOID': [],\r\n",
    "            'STATE': [],\r\n",
    "            'COUNTY': []\r\n",
    "        }\r\n",
    "\r\n",
    "    # replace unessecary strings with blank\r\n",
    "    \r\n",
    "    replace_str = ['Summary level: 150', 'state', 'county', 'tract', 'block group', ' ', ':', ',']\r\n",
    "\r\n",
    "    # iterate throguh items of returned geogeographies from us census api \r\n",
    "    for item in geographies.items():\r\n",
    "        # get the second item in the tuple\r\n",
    "        geoid = item[1]\r\n",
    "        # remove strings in replace_str list in string\r\n",
    "        geoid = re.sub('|'.join(replace_str), '', str(geoid))\r\n",
    "        # split by > to get seperated census ids \r\n",
    "        geoids = str(geoid).split('>')\r\n",
    "        # append to dictionary lists for each census id \r\n",
    "        geoid_dict['STATE'].append(geoids[0])\r\n",
    "        geoid_dict['COUNTY'].append(geoids[1])\r\n",
    "\r\n",
    "        # if county is select then geoid is county + state\r\n",
    "        if level == 'county':\r\n",
    "            geoid_dict['GEOID'].append(geoids[0] + geoids[1])\r\n",
    "        \r\n",
    "        # if tract is level then append tract and GEOID is county + state + tract\r\n",
    "        elif level == 'tract':\r\n",
    "            geoid_dict['TRACT'].append(geoids[2])\r\n",
    "            geoid_dict['GEOID'].append(geoids[0] + geoids[1] + geoids[2])\r\n",
    "        \r\n",
    "        # if block group is level then append block group and GEOID is county + state + tract + block group\r\n",
    "        elif level == 'blockgroup':\r\n",
    "            geoid_dict['TRACT'].append(geoids[2])\r\n",
    "            geoid_dict['BLOCK_GROUP'].append(geoids[3])\r\n",
    "            geoid_dict['GEOID'].append(geoids[0] + geoids[1] + geoids[2] + geoids[3])\r\n",
    "    \r\n",
    "    geoid_df = pd.DataFrame.from_dict(geoid_dict)\r\n",
    "\r\n",
    "    geoid_df.set_index('GEOID', inplace=True)\r\n",
    "\r\n",
    "    return geoid_df\r\n",
    "\r\n",
    "    \r\n",
    "def geoid_from_df(df: pd.DataFrame, level:str) -> pd.DataFrame:\r\n",
    "\r\n",
    "    \"Return the GEOID from the dataframe that is returned from the ACS calls\"\r\n",
    "    \r\n",
    "    if level not in ['county', 'tract', 'blockgroup']:\r\n",
    "        raise ValueError('Invalid level')\r\n",
    "    \r\n",
    "    # reset index so we can handle the census object that is returned for the id column\r\n",
    "    df = df.reset_index()\r\n",
    "\r\n",
    "    df = df.rename(columns={\"index\": \"id\"})\r\n",
    "    \r\n",
    "    geoid = df[['id']].astype(str)\r\n",
    "\r\n",
    "    # Get split columns on colon\r\n",
    "\r\n",
    "    geoid = geoid['id'].str.split(\":\",expand=True)\r\n",
    "\r\n",
    "    if level == 'county':\r\n",
    "        columns = ['STATE', 'COUNTY']\r\n",
    "        parse_nbr = [3,4]\r\n",
    "    elif level == 'tract':\r\n",
    "        columns = ['STATE', 'COUNTY', 'TRACT']\r\n",
    "        parse_nbr = [3,4,5]\r\n",
    "    elif level == 'blockgroup':\r\n",
    "        columns = ['STATE', 'COUNTY', 'TRACT', 'BLOCK_GROUP']\r\n",
    "        parse_nbr = [3,4,5,6]\r\n",
    "    \r\n",
    "\r\n",
    "    # get all of the census id columns from the split\r\n",
    "    geoid = geoid[parse_nbr]\r\n",
    "    \r\n",
    "    # force set the geoid columns by position\r\n",
    "    geoid.columns = columns\r\n",
    "    \r\n",
    "    # add all columns together to get GEOID based on level\r\n",
    "\r\n",
    "    if level == 'county':\r\n",
    "        geoid['GEOID'] = geoid['STATE'] + geoid['COUNTY']\r\n",
    "    elif level == 'tract':\r\n",
    "        geoid['GEOID'] = geoid['STATE'] + geoid['COUNTY'] + geoid['TRACT']\r\n",
    "    elif level == 'blockgroup':\r\n",
    "        geoid['GEOID'] = geoid['STATE'] + geoid['COUNTY'] + geoid['TRACT'] + geoid['BLOCK_GROUP']\r\n",
    "\r\n",
    "    # Apply a replacement to all columns to obtain cleaned geoid \r\n",
    "\r\n",
    "    geoid['GEOID'] = geoid['GEOID'].apply(lambda s: re.sub('|'.join(['> block group', '> tract', '> county']), '', str(s)))\r\n",
    "\r\n",
    "    # drop the unessecary columns\r\n",
    "\r\n",
    "    geoid = geoid.drop(columns=columns)\r\n",
    "    \r\n",
    "    # concat new columns and passed dataframe\r\n",
    "\r\n",
    "    df = pd.concat([df,geoid], axis=1)\r\n",
    "\r\n",
    "    # drop id columns and set GEOID index so concat works\r\n",
    "\r\n",
    "    df.drop(columns=['id'], inplace=True)\r\n",
    "\r\n",
    "    df.reset_index()\r\n",
    "\r\n",
    "    df.set_index('GEOID', inplace=True) \r\n",
    "\r\n",
    "\r\n",
    "    return df\r\n",
    "\r\n",
    "\r\n",
    "def get_acs_data(acs_data_dict: dict, state_code:str, year:int, level:str, acs_type:str, key=None) -> pd.DataFrame:\r\n",
    "\r\n",
    "    \"\"\"This function will return a dataframe with the ACS data for each chunk\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "    if acs_type not in ['acs5', 'acs1']:\r\n",
    "        raise ValueError('Invalid acs type')\r\n",
    "\r\n",
    "    if level not in ['county', 'tract', 'blockgroup']:\r\n",
    "        raise ValueError('Invalid level')\r\n",
    "\r\n",
    "    if year not in [2010, 2011, 2013,2014, 2015, 2016, 2017, 2018, 2019, 2020]:\r\n",
    "        raise ValueError('Invalid year')\r\n",
    "\r\n",
    "\r\n",
    "    def _chunked(dd, size):\r\n",
    "        \r\n",
    "        \"\"\"A generator to break the passed dictionary into chunks that can be iterated over\"\"\"\r\n",
    "\r\n",
    "        it = iter(dd)\r\n",
    "        while True:\r\n",
    "            p = tuple(itertools.islice(it, size))\r\n",
    "            if not p:\r\n",
    "                break\r\n",
    "            yield p\r\n",
    "\r\n",
    "    # get the chunk size from the acs_dd dictionary\r\n",
    "\r\n",
    "    chunks = int(len(list(acs_data_dict.items()))/10)\r\n",
    "\r\n",
    "\r\n",
    "    if level == 'county':\r\n",
    "        census = censusdata.censusgeo([('state', state_code), ('county', '*')])\r\n",
    "    elif level == 'tract':\r\n",
    "        census = censusdata.censusgeo([('state', state_code), ('county', '*'), ('tract', '*')])\r\n",
    "    elif level == 'blockgroup':\r\n",
    "        census = censusdata.censusgeo([('state', state_code), ('county', '*'), ('tract', '*'), ('block group', '*')])\r\n",
    "\r\n",
    "    if key is None:\r\n",
    "    # get geoids for pass in state code\r\n",
    "        boundaries = censusdata.geographies(census, 'acs5', year)\r\n",
    "    else:\r\n",
    "        boundaries = censusdata.geographies(census, 'acs5', year, key=key)\r\n",
    "\r\n",
    "    # curate reference and dataframe to concat on as we iterate through the chunks \r\n",
    "\r\n",
    "    geoid_df = get_geoid_reference_df(boundaries, level)\r\n",
    "\r\n",
    "    # using reference curate the dataframe and assign the GEOID index to concat on\r\n",
    "\r\n",
    "    census_df_list = []\r\n",
    "\r\n",
    "    # iterate over the dictionary in chunks\r\n",
    "    for chunk in _chunked(acs_dd, chunks):\r\n",
    "\r\n",
    "        # for var in chunk:\r\n",
    "        if key is None:\r\n",
    "        #Get the census data from the API\r\n",
    "            census_data_df = censusdata.download(acs_type, year, census, list(chunk)).rename(columns=acs_dd)\r\n",
    "        else:\r\n",
    "            census_data_df = censusdata.download(acs_type, year, census,  list(chunk), key).rename(columns=acs_dd)\r\n",
    "\r\n",
    "        #Pulling out the tract number from the index\r\n",
    "        acs_df = geoid_from_df(census_data_df, level)\r\n",
    "\r\n",
    "        census_df_list.append(acs_df)\r\n",
    "        # acs_df = None\r\n",
    "\r\n",
    "    census_df = pd.concat([geoid_df, pd.concat(census_df_list, axis=1)], axis=1)\r\n",
    "\r\n",
    "    census_df['year'] = year\r\n",
    "\r\n",
    "    census_df['level'] = level\r\n",
    "\r\n",
    "   # concat all the dataframes together \r\n",
    "    return census_df\r\n",
    "\r\n",
    "\r\n",
    "def get_aggregated_acs_data(acs_dd:dict, st_fips_df:pd.DataFrame, year:int, level:str, acs_type:str, key:str) -> pd.DataFrame:\r\n",
    "    \r\n",
    "    \"\"\"This function will return a dataframe with the ACS data for each chunk\"\"\"\r\n",
    "\r\n",
    "    if level not in ['county', 'tract', 'blockgroup', 'all']:\r\n",
    "        raise ValueError('Invalid level')\r\n",
    "\r\n",
    "\r\n",
    "    try:\r\n",
    "    # get the state codes from the state fips csv file\r\n",
    "        state_codes = st_fips['STATE']\r\n",
    "    except:\r\n",
    "        raise ValueError('State code column not found, make sure state code column in CSV is labeled as STATE')\r\n",
    "        sys.exit(1)\r\n",
    "\r\n",
    "        \r\n",
    "\r\n",
    "    # create an empty list so we can append all of the 50 state data to it \r\n",
    "    \r\n",
    "    tract_lst = []\r\n",
    "    block_group_lst = []\r\n",
    "    county_lst = []\r\n",
    "    any_lst = []\r\n",
    "\r\n",
    "    # iterate over the state codes and get the ACS data for each state\r\n",
    "    for state in state_codes:\r\n",
    "        if level == 'all':\r\n",
    "        # get the ACS data for each state\r\n",
    "            raw_df = get_acs_data(acs_dd, state, year, 'county', acs_type, key)\r\n",
    "            raw_df = get_acs_data(acs_dd, state, year, 'tract', acs_type, key)\r\n",
    "            raw_df = get_acs_data(acs_dd, state, year, 'blockgroup', acs_type, key)\r\n",
    "            tract_lst.append(raw_df)\r\n",
    "            block_group_lst.append(raw_df)\r\n",
    "            county_lst.append(raw_df)\r\n",
    "        else:    \r\n",
    "            # append the ACS data for each state to the empty list\r\n",
    "            raw_df = get_acs_data(acs_dd, state, year, level, acs_type, key)\r\n",
    "            any_lst.append(raw_df)\r\n",
    "\r\n",
    "\r\n",
    "    if level == 'all':\r\n",
    "        #concat seperate dataframes together\r\n",
    "        tract_df = pd.concat(tract_lst, axis=0)\r\n",
    "        block_group_df = pd.concat(block_group_lst, axis=0)\r\n",
    "        county_df = pd.concat(county_lst, axis=0)\r\n",
    "        return tract_df, block_group_df, county_df\r\n",
    "\r\n",
    "    else:\r\n",
    "        # concat all the dataframes together \r\n",
    "        any_df = pd.concat(any_lst, axis=0)\r\n",
    "\r\n",
    "        return any_df\r\n",
    "    \r\n",
    "    # write the ACS data to a csv file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# set absolute path to join on for reading and writing\r\n",
    "abspath = os.path.dirname(os.path.normpath(os.path.abspath(os.path.dirname(''))))\r\n",
    "\r\n",
    "# read in ACS data to obtain keys and formatted column names from source config folder\r\n",
    "acs_dd = json.load(open(os.path.join(abspath, 'src', 'refs', 'acs_dd.json')))\r\n",
    "\r\n",
    "# open state fips codes csv file in pandas\r\n",
    "st_fips = pd.read_csv(os.path.join(abspath, 'src', 'refs', 'state_fips.csv'), dtype=str)\r\n",
    "\r\n",
    "# get api key from config json file\r\n",
    "\r\n",
    "config = json.load(open(os.path.join(abspath, 'config.json')))\r\n",
    "\r\n",
    "key = config['key'][0]\r\n",
    "\r\n",
    "todays_date = date.today()\r\n",
    "\r\n",
    "# year = todays_date.year\r\n",
    "\r\n",
    "year = 2019 # hard coded year to get since 2019 is the only thing that is available \r\n",
    "\r\n",
    "state_code = '37'\r\n",
    "\r\n",
    "key = '79d3d777f9c930f33a654446bf2e40f425c9b247'\r\n",
    "\r\n",
    "# raw_df = get_acs_data(acs_dd, state_code, year, 'blockgroup', 'acs5', key)\r\n",
    "\r\n",
    "# raw_df.to_csv(os.path.join(abspath, 'data', 'raw', f'acs_{year}_raw.csv'))\r\n",
    "\r\n",
    "all_50_grp_df = get_aggregated_acs_data(acs_dd, st_fips, year, 'blockgroup', 'acs5', key)\r\n",
    "\r\n",
    "all_50_grp_df.to_csv(os.path.join(abspath, 'data', 'raw', f'acs_all_50_{year}_raw.csv'))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "d83ad3a39640e45593c9df71430ee3ad7d7609991877e929a0498be1b4dbd18b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}